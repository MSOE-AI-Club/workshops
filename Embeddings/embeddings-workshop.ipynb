{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings\n",
    "===\n",
    "MAIC - Spring, Week 4<br>\n",
    "```\n",
    "  _____________\n",
    " /0   /     \\  \\\n",
    "/  \\ M A I C/  /\\\n",
    "\\ / *      /  / /\n",
    " \\___\\____/  @ /\n",
    "          \\_/_/\n",
    "```\n",
    "(Rosie is not needed!)\n",
    "\n",
    "Prereqs:\n",
    "- Install [VSCode](https://code.visualstudio.com/)\n",
    "- Install [Python](https://www.python.org/downloads/)\n",
    "- Ensure you can run notebooks in VSCode.\n",
    "\n",
    "<span style=\"color:#ff5555;font-weight:bold;font-size:1.5rem;\">\n",
    "    STOP\n",
    "</span>\n",
    "\n",
    "... or keep going if you want to work ahead.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings are an extremely useful tool in modern machine learning, allowing raw text to be transformed into numerical representations that models can understand.\n",
    "They are also a popular interview question to test a candidateâ€™s understanding of vector spaces, similarity metrics, and real-world applications.\n",
    "Beyond that, embeddings are incredibly common in ML, powering everything from search engines and recommendation systems to chatbots and fraud detection.\n",
    "You'll see embeddings being used everywhere if you look! Here are just some models, projects, and papers that make use of embeddings:\n",
    "- [The original transformer paper - the basis of modern LLMs](https://arxiv.org/pdf/1706.03762)\n",
    "- [RAG systems - often used to give LLMs comprehensive access to much more information than they could normally use at once](https://en.wikipedia.org/wiki/Retrieval-augmented_generation)\n",
    "- [Image generations models such as Stable Diffusion](https://en.wikipedia.org/wiki/Stable_Diffusion)\n",
    "  - Note: images are generated *in embedding space*!\n",
    "- [Audio-continuation models such as RAVE](https://github.com/acids-ircam/RAVE)\n",
    "- Modern image search makes extensive use of embeddings\n",
    "- Modern recommendation algorithms also use embeddings\n",
    "- Even some papers published by MSOE students involve the use of embeddings! Here are a few:\n",
    "  - [Agent simulation with LLMs](https://arxiv.org/pdf/2409.13753)\n",
    "  - [Strategy masking - a technique to control model behavior](https://arxiv.org/pdf/2501.05501)\n",
    "\n",
    "**What *are* Embeddings?**\n",
    "\n",
    "At the lowest level, an embedding is just stored as a list of numbers.\n",
    "\n",
    "[img of list of numbers - idea for imgs: we can link to imgs hosted on this repo]\n",
    "\n",
    "This list of numbers is best interpreted as a point or direction in some very high-dimensional space that represents something. In the case of text-based models, embeddings are used to represent words and sentences. Let's assume we already have a model that can embed any word.\n",
    "\n",
    "[img]\n",
    "\"Some\" -> [numbers]\n",
    "\"Embedded\" -> [numbers]\n",
    "\"Words\" -> [numbers]\n",
    "\n",
    "In practice, embeddings range from tens of dimensions to over 1000. For simplicity, let's only conceptualize things in two dimensions for now.\n",
    "\n",
    "[img of numbers as point in space]\n",
    "\n",
    "But how do we actually interpret these directions in space as being words? The answer is that different directions in the space represent different aspects of a word -\n",
    "- one direction may encode \"past tense,\"\n",
    "- another may enode \"physical verb,\"\n",
    "- and a third may encode \"fast-ness.\"\n",
    "\n",
    "In the case above, the embedding of the word \"ran\" may point in the average of the directions encoding \"past tense,\" \"physical verb,\" and \"fast-ness.\"\n",
    "\n",
    "[Here is a one-minute video that illustrates this concept using real-world embeddings.](https://www.youtube.com/watch?v=FJtFZwbvkI4)\n",
    "\n",
    "---\n",
    "\n",
    "<span style=\"color:#55ff55;font-weight:bold;font-size:1.5rem;\">\n",
    "    GO\n",
    "</span>\n",
    "\n",
    "**That seems neat. How can *I* use embeddings?**\n",
    "\n",
    "Let's set things up!\n",
    "\n",
    "It's really easy to get started with embeddings. You can even run small embedding models on your laptop!\n",
    "\n",
    "We'll be using `sentence-transformers` to run [all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) - a model that embeds sentences into 384 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shouldn't take longer that 5 mins\n",
    "%pip install sentence-transformers\n",
    "%pip install tf-keras\n",
    "%pip instal numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\") # Our model of choice is supplied here. You can find many more on huggingface: https://huggingface.co/models?sort=trending&search=embed\n",
    "embedding = model.encode(\"This is an embedded text example.\")\n",
    "\n",
    "print(embedding) # our embeddings are just lists of numbers stored as Numpy arrays. Numpy is just a library that makes it easier to manipulate arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#ff5555;font-weight:bold;font-size:1.5rem;\">\n",
    "    STOP\n",
    "</span>\n",
    "\n",
    "... or keep going if you want to work ahead.\n",
    "\n",
    "---\n",
    "\n",
    "Now that we (hopefully) have a working embedding model, let's put it to use.\n",
    "\n",
    "Let's first try the example from the previously linked 3Blue1Brown video. But before that, we need to understand how to measure \"distance\" in embedding space.\n",
    "\n",
    "[TODO - explain cosine similarity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_uncle = model.encode(\"uncle\")\n",
    "emb_aunt = model.encode(\"aunt\")\n",
    "emb_man = model.encode(\"man\")\n",
    "emb_woman = model.encode(\"woman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(emb_uncle, emb_aunt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(emb_uncle - emb_man + emb_woman, emb_aunt) # not working - maybe use a word-level model? But I wanted to keep things simple with only one model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "more on visualizing embeddings\n",
    "- bar plot\n",
    "- img\n",
    "- pca\n",
    "\n",
    "some search task\n",
    "\n",
    "some clustering task\n",
    "\n",
    "maybe: high level of embeddings in transformer/attention?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
