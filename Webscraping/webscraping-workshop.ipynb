{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Webscraping\n",
    "===\n",
    "MAIC - Spring, Week 2<br>\n",
    "```\n",
    "  _____________\n",
    " /0   /     \\  \\\n",
    "/  \\ M A I C/  /\\\n",
    "\\ / *      /  / /\n",
    " \\___\\____/  @ /\n",
    "          \\_/_/\n",
    "```\n",
    "(Rosie is not needed!)\n",
    "\n",
    "Prereqs:\n",
    "- Install [VSCode](https://code.visualstudio.com/)\n",
    "- Install [Python](https://www.python.org/downloads/)\n",
    "- Ensure you can run notebooks in VSCode.\n",
    "\n",
    "<span style=\"color:#ff5555;font-weight:bold;font-size:1.5rem;\">\n",
    "    STOP\n",
    "</span>\n",
    "\n",
    "... or keep going if you want to work ahead.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is webscraping?**\n",
    "\n",
    "Are you in need of data? Maybe you want to analyze some data for insights. Or maybe you just want to train a model. In any case, you may be able to get the data you need via webscraping!\n",
    "\n",
    "Webscraping is the process of *automatically* extracting data from websites. You can manually extract website data on your browser via \"inspect,\" but automating this process is ideal if you need anything more than a few samples.\n",
    "\n",
    "- Go to any website (for instance, the [MAIC](https://msoe-maic.com/) site).\n",
    "- Right-click anywhere on the page. Select the \"inspect\" option or something labeled similarly. This is usually at the bottom of the pop-up menu.\n",
    "- Note the window that opened. It contains the raw HTML (and possibly JS/CSS) site data. This is what we want to scrape automatically.\n",
    "- Use the element selector at the top left of the inspect window to see the HTML of specific elements.\n",
    "\n",
    "---\n",
    "\n",
    "<span style=\"color:#55ff55;font-weight:bold;font-size:1.5rem;\">\n",
    "    GO\n",
    "</span>\n",
    "\n",
    "**That's cool. How can I scrape automatically?**\n",
    "\n",
    "Let's try scraping the MAIC leaderboard!\n",
    "\n",
    "Basic scraping only needs the `requests` library which comes with Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "URL = 'https://msoe-maic.com'\n",
    "\n",
    "html = requests.get(URL).text # Make a request to the URL and get the HTML via `.text`\n",
    "print(html[:500]) # Print some of the resulting HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This html now contains the leaderboard for us to extract. But how do we extract it?\n",
    "\n",
    "One easy way is to *inspect* the page on your browser, and to see if the HTML can easily identify the leaderboard. It seems that the leaderboard element is in the \"leaderboard-table\" class:\n",
    "\n",
    "```html\n",
    "<table border=\"1\" class=\"dataframe leaderboard-table\" id=\"df_data\">\n",
    "    ...\n",
    "</table>\n",
    "```\n",
    "\n",
    "We could try looking for \"leaderboad-table\" in the html string, but there's a better way. `Beautifulsoup` is a Python library that makes parsing HTML easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install beautifulsoup4 # Install BeautifulSoup and possibly restart your notebook, being sure to re-run prior cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup # We can now use BeautifulSoup to parse the HTML\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser') \n",
    "print(soup.prettify()[:500]) # print it as before, but now it's prettified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use BeautifulSoup to find the \"leaderboard-table\" element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the table element with class \"leaderboard-table\"\n",
    "\n",
    "leaderboard_table = soup.find('table', {'class': 'leaderboard-table'})\n",
    "\n",
    "print(leaderboard_table.prettify()[:500]) # print the first 500 characters of the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only can Beautifulsoup find the element, it also allows us to easily extract the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract table data into a list of dictionaries\n",
    "\n",
    "rows = leaderboard_table.find_all('tr') # Find all rows in the table\n",
    "header = [cell.text for cell in rows[0].find_all('th')] # Get the header row\n",
    "data = [\n",
    "    {header[i]: cell.text for i, cell in enumerate(row.find_all('td'))} # Create a dictionary for each row using the header to name the keys\n",
    "    for row in rows[1:]\n",
    "]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty neat, right?\n",
    "\n",
    "<span style=\"color:#ff5555;font-weight:bold;font-size:1.5rem;\">\n",
    "    STOP\n",
    "</span>\n",
    "\n",
    "... or keep going if you want to work ahead.\n",
    "\n",
    "---\n",
    "\n",
    "TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
